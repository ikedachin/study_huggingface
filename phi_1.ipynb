{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuggingfaceからMicrosoftのPhi-1.5を使ってみよう\n",
    "\n",
    "https://huggingface.co/microsoft/phi-1_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colab\n",
    "https://drive.google.com/file/d/1UwTu5I6HW1mOnxMZmVPgvofrlB_zv35q/view?usp=sharing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #01 ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #02 GPU / MPS / CPUの選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #03 トークナイザーとモデルのダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device(device)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-1_5\", torch_dtype=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-1_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #04 出力を確認しながら推論させてみよう\n",
    "## #04-1 トークナイザーを使って、文章をトークンIDに変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = 'please tell me how to play a fiddle.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", return_attention_mask=False)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.input_ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #04-2 トークンIDを文章に戻す方法を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(inputs.input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #04-3 Phi-1.5モデルに入力トークンIDを渡して出力させよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(inputs.input_ids, max_length=200)\n",
    "# outputs = model.generate(**inputs, max_length=200) # <- こちらの書き方でもOK\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #04-4 モデルから出てきたトークンIDを文章に戻す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_text = tokenizer.batch_decode(outputs)[0]\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_text = tokenizer.decode(outputs[0])\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #05 DXクエストについて聞いてみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = 'Please tell me about manabi-DX-Quest.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(input_text, return_tensors=\"pt\", return_attention_mask=False)\n",
    "outputs = model.generate(inputs.input_ids, max_length=200)\n",
    "output_text = tokenizer.batch_decode(outputs)[0]\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #06 プログラムを書かせてみよう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #06-1 関数の書き方（Pythonのおさらい）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# まず、関数の例\n",
    "def add_num(a, b):\n",
    "    '''引数の二つの値を足す。   <- Docstringsという\n",
    "    '''\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "added_number = add_num(4, 5)\n",
    "added_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1からnまでの数字で素数をプリントする関数\n",
    "\n",
    "text = '''\n",
    "def print_prime(n):\n",
    "    \"\"\"Print all primes between 1 and n\n",
    "    \"\"\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a/bをした時に整数ならinteger、小数点があるならfloatと返す関数\n",
    "text = '''\n",
    "def check_division_type(a, b):\n",
    "    \"\"\"When performing a/b, return \"integer\" if the result is an integer, and \"float\" if the result has a decimal point.\n",
    "    \"\"\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text, return_tensors='pt', return_attention_mask=False)\n",
    "outputs = model.generate(inputs.input_ids, max_length=400)\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #07 ファインチューニングに向けて、モデルの設定を確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "phi15_config = AutoConfig.from_pretrained(\"microsoft/phi-1_5\")\n",
    "phi15_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #08 データセットのストリーミング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('oscar-corpus/OSCAR-2201', 'en', split='train', streaming=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(iter(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"oscar-corpus/OSCAR-2201\",\n",
    "                        token=\"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\",\n",
    "                        # use_auth_token=True, # required\n",
    "                        language=\"ar\", \n",
    "                        streaming=True, # optional\n",
    "                        split=\"train\", # optional, but the dataset only has a train split\n",
    "                        trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataset:\n",
    "    print(d) # prints documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #09 参考：HuggingFaceへのログイン\n",
    "モデルやデータセットをアップロードするにはログインが必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コマンドラインでの実行方法\n",
    "# huggingface-cli login"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hug_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
