{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/microsoft/phi-1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac22c994ec24e77bcf9720115ceb412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  43%|####2     | 1.21G/2.84G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873adcac06084bb38f5db8c71a0b9310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/74.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7018ecdd89784ac181214820ad5ca5ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/237 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb09bc221ae45bd9358bcda64fbe204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970024ef449244f7949a0084dda14571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d640c03c56e442d39786b3cf8b453148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a028614036451ea94ad15fad16dadb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f33563a26d4d95a24e40c981c7585c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "torch.set_default_device(\"mps\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-1\", torch_dtype=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 4299,  3601,    62, 35505,     7,    77,  2599,   198, 50285, 37811,\n",
       "           198, 50285, 18557,   477,   778,   999,  1022,   352,   290,   299,\n",
       "           198, 50285, 37811]], device='mps:0')}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "inputs = tokenizer('''def print_prime(n):\n",
    "   \"\"\"\n",
    "   Print all primes between 1 and n\n",
    "   \"\"\"''', return_tensors=\"pt\", return_attention_mask=False)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4299,  3601,    62, 35505,     7,    77,  2599,   198, 50285, 37811,\n",
       "           198, 50285, 18557,   477,   778,   999,  1022,   352,   290,   299,\n",
       "           198, 50285, 37811,   198, 50285,  1640,   997,   287,  2837,     7,\n",
       "            17,    11,   299,    10,    16,  2599,   198, 50281,  1640,  1312,\n",
       "           287,  2837,     7,    17,    11,   997,  2599,   198, 50277,   361,\n",
       "           997,  4064,  1312,  6624,   657,    25,   198, 50273,  9032,   198,\n",
       "         50281, 17772,    25,   198, 50277,  4798,     7, 22510,     8,   628,\n",
       "         50256,   198,   198,  6738, 19720,  1330,  7343,   198,   198,  4299,\n",
       "          1064,    62, 17470,   395,    62, 48101,    62,  1659,    62,  4868,\n",
       "             7,  4528,    25,  7343,    58,   600, 12962,  4613,   493,    25,\n",
       "           198, 50284, 37811,   198, 50284, 35561,   262, 18197,  3967, 18253,\n",
       "           326,   318,  2659, 12843,   416,   477,   262,  3146,   287,   262,\n",
       "          5128,  1351,    13,   628, 50284, 42035,    25,   198, 50284,  4528,\n",
       "           357,  8053,    58,   600,    60,  2599,   317,  1351,   286, 37014,\n",
       "            13,   628, 50284, 35561,    25,   198, 50284,   600,    25,   383,\n",
       "         18197,  3967, 18253,   326,   318,  2659, 12843,   416,   477,   262,\n",
       "          3146,   287,   262,  5128,  1351,    13,   198, 50284, 37811,   628,\n",
       "         50284,     2,  9938,   262,  5415,  1271,   287,   262,  1351,   198,\n",
       "         50284,  9806,    62, 22510,   796,  3509,     7,  4528,     8,   628,\n",
       "         50284,     2, 20768,  1096,   262,  1255,   284,   262,  5415,  1271]],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.generate(**inputs, max_length=200)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def print_prime(n):\n",
      "   \"\"\"\n",
      "   Print all primes between 1 and n\n",
      "   \"\"\"\n",
      "   for num in range(2, n+1):\n",
      "       for i in range(2, num):\n",
      "           if num % i == 0:\n",
      "               break\n",
      "       else:\n",
      "           print(num)\n",
      "\n",
      "<|endoftext|>\n",
      "\n",
      "from typing import List\n",
      "\n",
      "def find_smallest_multiple_of_list(li: List[int]) -> int:\n",
      "    \"\"\"\n",
      "    Returns the smallest positive integer that is divisible by all the numbers in the input list.\n",
      "\n",
      "    Args:\n",
      "    li (List[int]): A list of integers.\n",
      "\n",
      "    Returns:\n",
      "    int: The smallest positive integer that is divisible by all the numbers in the input list.\n",
      "    \"\"\"\n",
      "\n",
      "    # Find the maximum number in the list\n",
      "    max_num = max(li)\n",
      "\n",
      "    # Initialize the result to the maximum number\n"
     ]
    }
   ],
   "source": [
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer('''Please tell me about manabi DX Quest.''', return_tensors=\"pt\", return_attention_mask=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please tell me about manabi DX Quest.\\n\\nMana DX is a fictional place where people can earn money.\\n\\nMana DX is the only place where people can live.\\n\\nMana DX is the only place where people can live.\\n\\nMana DX is the only place where people can live.\\n\\nMana DX is the only place where people can live.\\n\\nMana DX is the only place where people can live.\\n\\nMana DX is the only place where people can live.\\n\\nMana DX is the only place where people can live.\\n\\nMana DX is the only place where people can live.\\n\\nMana DX is the only place where people can live.\\n\\nMana DX is the only place where people can live.\\n\\nMana DX is the only place where people can\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(**inputs, max_length=200)\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please tell me about manabi DX Quest.\n",
      "\n",
      "Mana DX is a fictional place where people can earn money.\n",
      "\n",
      "Mana DX is the only place where people can live.\n",
      "\n",
      "Mana DX is the only place where people can live.\n",
      "\n",
      "Mana DX is the only place where people can live.\n",
      "\n",
      "Mana DX is the only place where people can live.\n",
      "\n",
      "Mana DX is the only place where people can live.\n",
      "\n",
      "Mana DX is the only place where people can live.\n",
      "\n",
      "Mana DX is the only place where people can live.\n",
      "\n",
      "Mana DX is the only place where people can live.\n",
      "\n",
      "Mana DX is the only place where people can live.\n",
      "\n",
      "Mana DX is the only place where people can live.\n",
      "\n",
      "Mana DX is the only place where people can\n"
     ]
    }
   ],
   "source": [
    "texts = text.split(\"\\\\n\")\n",
    "for text in texts:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hug_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
